---
- name: Update repositories cache and install java
  apt:
    name: default-jdk
    update_cache: yes
  sudo: yes

- name: Create destination folder
  file:
    path: "{{ dest }}"
    state: directory
    owner: "{{ server_user }}"
    group: "{{ server_group }}"
    mode: 0755
  sudo: yes
  sudo_user: "{{ server_user }}"

- name: Download spark-hadoop
  get_url:
    url: "{{ package_url }}"
    dest: /tmp/spark-2.1.1-bin-hadoop2.7.tgz
    mode: 0440
  sudo: yes
  sudo_user: "{{ server_user }}"

- name: Decompress spark-hadoop
  unarchive:
    src: /tmp/spark-2.1.1-bin-hadoop2.7.tgz
    dest: "{{ dest }}/"
    copy: no
    owner: "{{ server_user }}"
    group: "{{ server_user }}"
    mode: 0755
  sudo: yes
  sudo_user: "{{ server_user }}"

- name: Kill all existing spark services
  shell: "ps aux | grep spark | grep -v grep | awk '{printf(\"%s \"), $2}' | xargs kill -9"
  sudo: yes
  sudo_user: "{{ server_user }}"
  tags:
    - update_services
    - update_spark_repo

- name: Start spark master
  command: ./sbin/start-master.sh
  args:
    chdir: "{{ dest }}/spark-2.1.1-bin-hadoop2.7"
  sudo: yes
  sudo_user: "{{ server_user }}"
  tags:
    - update_services
    - update_spark_repo

- name: Start spark slave
  command: ./sbin/start-slave.sh spark://yiistable:7077
  args:
    chdir: "{{ dest }}/spark-2.1.1-bin-hadoop2.7"
  sudo: yes
  sudo_user: "{{ server_user }}"
  tags:
    - update_services
    - update_spark_repo
